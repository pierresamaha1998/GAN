{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxlEXjsOVFZj"
      },
      "source": [
        "# Generative Adversarial Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhaMFKzXVFZp"
      },
      "source": [
        "Generative Adversarial Networks are used to generate images that never existed before.\n",
        "\n",
        "G for Generative - this is a model that takes an input as a random noise singal and then outputs an image.\n",
        "\n",
        "A for Adversarial - this is the discriminator, the opponent of the generator. This is capable of learning about objects, animals or other features specified. \n",
        "\n",
        "Using this example, once the discriminator has been trained, showing the discriminator a picture that isn't a dog it will return a 0. Whereas, if you show it a dog it will return a 1.\n",
        "\n",
        "N for Network - meaning the generator and discriminator are both neural networks.\n",
        "\n",
        "we input a random noise signal into the generator. The generator creates some images which is used for training the discriminator. We provide the discriminator with some features/images we want it to learn and the discriminator outputs probabilities. These probabilities can be rather high as the discriminator has only just started being trained. The values are then assessed and identified. The error is calculated and these are backpropagated through the discriminator, where the weights are updated.\n",
        "\n",
        "Next we train the generator. We take the batch of images that it created and put them through the discriminator again. We do not include the feature images. The generator learns by tricking the discriminator into it outputting false positives.\n",
        "\n",
        "The discriminator will provide an output of probabilities. The values are then assessed and compared to what they should have been. The error is calculated and backpropagated through the generator and the weights are updated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c6RS_G9VFZr"
      },
      "source": [
        "### Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIaGVYBsVFZs"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tqdm import tqdm_notebook as tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihMeRqXJVLJn",
        "outputId": "2762f1bd-2a88-478c-d96e-ad9a115b6e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jf9rD3uVFZv"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "batchSize = 64\n",
        "imageSize = 64\n",
        "\n",
        "# 64x64 images!\n",
        "transform = transforms.Compose([transforms.Resize(64),\n",
        "                                transforms.CenterCrop(64),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_data = datasets.ImageFolder('/content/drive/My Drive/Kaggle/GAN/input/all-gogs/', transform=transform)\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(train_data, shuffle=True,\n",
        "                                           batch_size=batch_size)\n",
        "\n",
        "imgs, label = next(iter(dataloader))\n",
        "imgs = imgs.numpy().transpose(0, 2, 3, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYf0hmIkVFZw"
      },
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    \"\"\"\n",
        "    Takes as input a neural network m that will initialize all its weights.\n",
        "    \"\"\"\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iv-w1L5_VFZx"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz=128, channels=3):\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        self.nz = nz\n",
        "        self.channels = channels\n",
        "        \n",
        "        def convlayer(n_input, n_output, k_size=4, stride=2, padding=0):\n",
        "            block = [\n",
        "                nn.ConvTranspose2d(n_input, n_output, kernel_size=k_size, stride=stride, padding=padding, bias=False),\n",
        "                nn.BatchNorm2d(n_output),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "            return block\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *convlayer(self.nz, 1024, 4, 1, 0), # Fully connected layer via convolution.\n",
        "           *convlayer(1024, 512, 4, 2, 1),\n",
        "            *convlayer(512, 256, 4, 2, 1),\n",
        "            *convlayer(256, 128, 4, 2, 1),\n",
        "            *convlayer(128, 64, 4, 2, 1),\n",
        "            nn.ConvTranspose2d(64, self.channels, 3, 1, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        # .view(-1) = Flattens the output into 1D instead of 2D\n",
        "        z = z.view(-1, self.nz, 1, 1)\n",
        "        img = self.model(z)\n",
        "        return img\n",
        "\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channels=3):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        self.channels = channels\n",
        "\n",
        "        def convlayer(n_input, n_output, k_size=4, stride=2, padding=0, bn=False):\n",
        "            block = [nn.Conv2d(n_input, n_output, kernel_size=k_size, stride=stride, padding=padding, bias=False)]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(n_output))\n",
        "            block.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return block\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *convlayer(self.channels, 32, 4, 2, 1),\n",
        "            *convlayer(32, 64, 4, 2, 1),\n",
        "            *convlayer(64, 128, 4, 2, 1, bn=True),\n",
        "            *convlayer(128, 256, 4, 2, 1, bn=True),\n",
        "            nn.Conv2d(256, 1, 4, 1, 0, bias=False),  # FC with Conv.\n",
        "        )\n",
        "\n",
        "    def forward(self, imgs):\n",
        "        logits = self.model(imgs)\n",
        "        out = torch.sigmoid(logits)\n",
        "    \n",
        "        return out.view(-1, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjpMr2GeVFZz"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "LR_G = 0.001\n",
        "LR_D = 0.0005\n",
        "\n",
        "beta1 = 0.5\n",
        "epochs = 20\n",
        "\n",
        "real_label = 0.9\n",
        "fake_label = 0\n",
        "nz = 128\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0ZTfJ2vVFZz"
      },
      "outputs": [],
      "source": [
        "netG = Generator(nz).to(device)\n",
        "netD = Discriminator().to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=LR_D, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=LR_G, betas=(beta1, 0.999))\n",
        "\n",
        "fixed_noise = torch.randn(25, nz, 1, 1, device=device)\n",
        "\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "epoch_time = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BmlO_1JVFZ0"
      },
      "outputs": [],
      "source": [
        "def plot_loss (G_losses, D_losses, epoch):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(\"Generator and Discriminator Loss - EPOCH \"+ str(epoch))\n",
        "    plt.plot(G_losses,label=\"G\")\n",
        "    plt.plot(D_losses,label=\"D\")\n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmptsCzcVFZ1"
      },
      "outputs": [],
      "source": [
        "def show_generated_img(n_images=5):\n",
        "    sample = []\n",
        "    for _ in range(n_images):\n",
        "        noise = torch.randn(1, nz, 1, 1, device=device)\n",
        "        gen_image = netG(noise).to(\"cpu\").clone().detach().squeeze(0)\n",
        "        gen_image = gen_image.numpy().transpose(1, 2, 0)\n",
        "        sample.append(gen_image)\n",
        "    \n",
        "    figure, axes = plt.subplots(1, len(sample), figsize = (64,64))\n",
        "    for index, axis in enumerate(axes):\n",
        "        axis.axis('off')\n",
        "        image_array = sample[index]\n",
        "        axis.imshow(image_array)\n",
        "        \n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXP49IKmVFZ1"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "    \n",
        "    start = time.time()\n",
        "    for ii, (real_images, train_labels) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        # train with real\n",
        "        netD.zero_grad()\n",
        "        real_images = real_images.to(device)\n",
        "        batch_size = real_images.size(0)\n",
        "        labels = torch.full((batch_size, 1), real_label, device=device)\n",
        "\n",
        "        output = netD(real_images)\n",
        "        errD_real = criterion(output, labels)\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "\n",
        "        # train with fake\n",
        "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "        fake = netG(noise)\n",
        "        labels.fill_(fake_label)\n",
        "        output = netD(fake.detach())\n",
        "        errD_fake = criterion(output, labels)\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        errD = errD_real + errD_fake\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        labels.fill_(real_label)  # fake labels are real for generator cost\n",
        "        output = netD(fake)\n",
        "        errG = criterion(output, labels)\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        optimizerG.step()\n",
        "        \n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "        \n",
        "        if (ii+1) % (len(dataloader)//2) == 0:\n",
        "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
        "                  % (epoch + 1, epochs, ii+1, len(dataloader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "            \n",
        "    plot_loss (G_losses, D_losses, epoch)\n",
        "    G_losses = []\n",
        "    D_losses = []\n",
        "    if epoch % 4 == 0:\n",
        "        show_generated_img()\n",
        "\n",
        "    epoch_time.append(time.time()- start)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ST13mEPZVFZ3"
      },
      "outputs": [],
      "source": [
        "print (\">> average EPOCH duration = \", np.mean(epoch_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIVy2_DmVFZ3"
      },
      "outputs": [],
      "source": [
        "show_generated_img(7)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aeae005699da9ee22f5f1999a0228188e87e61d9f977527a9e2e028c3963d1b8"
      }
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}